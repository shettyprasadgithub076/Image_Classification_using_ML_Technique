{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Neighbors Classifier(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage import io,transform,filters,color\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the images\n",
    "def preprocess_image(image_path):\n",
    "    image=io.imread(image_path)\n",
    "    image=color.rgb2gray(image)\n",
    "    blured_image=filters.gaussian(image,sigma=1)\n",
    "    resized_image=transform.resize(blured_image,(100,100))\n",
    "    \n",
    "    resized_image = np.fliplr(resized_image)\n",
    "    rotation_angle =random.uniform(-10, 10)\n",
    "    resized_image = transform.rotate(resized_image, rotation_angle)\n",
    "    \n",
    "    return resized_image.flatten()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the images from the respective folder\n",
    "trainfolder=\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\training_set\"\n",
    "class_names=[\"cats\",\"dogs\"]\n",
    "data=[]\n",
    "label=[]\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_path=os.path.join(trainfolder,class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "        if not image_name.startswith('_DS_Store'):\n",
    "            image_path=os.path.join(class_path,image_name)\n",
    "            pre_image=preprocess_image(image_path)\n",
    "            data.append(pre_image)\n",
    "            label.append(class_name)\n",
    "data=np.array(data)\n",
    "label=np.array(label)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2d=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#reshape the data into 3D to 2D\n",
    "print(data.shape)\n",
    "num_samples, height, width = data.shape\n",
    "data_2d = data.reshape(num_samples, height * width)\n",
    "'''\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(data_2d,label,test_size=0.2,random_state=42)\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train,y_train)\n",
    "knn_prediction=knn.predict(x_test)\n",
    "score=accuracy_score(knn_prediction,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train,x_test,y_train,y_test=train_test_split(data_2d,label,test_size=0.2,random_state=42)\n",
    "best_accuracy=0\n",
    "best_k=None\n",
    "\n",
    "for k in range(1,21):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    k_pred=knn.predict(x_test)\n",
    "    accuracy=accuracy_score(k_pred,y_test)\n",
    "    \n",
    "    if accuracy>best_accuracy:\n",
    "        best_accuracy=accuracy\n",
    "        best_k=k\n",
    "print(\"best_k\",k)\n",
    "print(\"best_accuracy\",best_accuracy)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy=0\n",
    "best_k=None\n",
    "best_prediction=None\n",
    "k_values=[]\n",
    "accuracy_values=[]\n",
    "for k in range(1,26):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    k_pred=knn.predict(x_test)\n",
    "    accuracy=accuracy_score(k_pred,y_test)\n",
    "    k_values.append(k)\n",
    "    accuracy_values.append(accuracy)\n",
    "    \n",
    "    print(f\"K:{k},Accuracy:{accuracy}\")\n",
    "    \n",
    "    if accuracy>best_accuracy:\n",
    "        best_accuracy=accuracy\n",
    "        best_k=k\n",
    "        best_prediction=k_pred\n",
    "print()\n",
    "print(\"best_k\",best_k)\n",
    "print(\"best_accuracy\",best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(k_values,accuracy_values,marker='o')\n",
    "plt.title(\"Accuracy Vs Number of Neighbors(k)\")\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing for unseen data\n",
    "\n",
    "best_model=KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_model.fit(x_train,y_train)\n",
    "new_image_path=[\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\dog.4132.jpg\"]\n",
    "new_data=[]\n",
    "for image_path in new_image_path:\n",
    "    preprocessed_image=preprocess_image(image_path)\n",
    "    new_data.append(preprocessed_image)\n",
    "new_data=np.array(new_data)\n",
    "\n",
    "#num_samples,h,w=new_data.shape\n",
    "#new_data=new_data.reshape(num_samples,h*w)\n",
    "print(new_data.shape)\n",
    "new_pred=best_model.predict(new_data)\n",
    "print(new_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without using any train_test_split method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfolder=\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\test_set\"\n",
    "class_names=[\"cats\",\"dogs\"]\n",
    "data_test=[]\n",
    "label_test=[]\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_path=os.path.join(testfolder,class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "        if not image_name.startswith('_DS_Store'):\n",
    "            image_path=os.path.join(class_path,image_name)\n",
    "            pre_image=preprocess_image(image_path)\n",
    "            data_test.append(pre_image)\n",
    "            label_test.append(class_name)\n",
    "data_test=np.array(data_test)\n",
    "label_test=np.array(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(data_2d,label)\n",
    "knn_prediction=knn.predict(data_test)\n",
    "score=accuracy_score(knn_prediction,label_test)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy=0\n",
    "best_k=None\n",
    "best_prediction=None\n",
    "k_values=[]\n",
    "accuracy_values=[]\n",
    "for k in range(1,26):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(data_2d,label)\n",
    "    k_pred=knn.predict(data_test)\n",
    "    accuracy=accuracy_score(k_pred,label_test)\n",
    "    k_values.append(k)\n",
    "    accuracy_values.append(accuracy)\n",
    "    \n",
    "    print(f\"K:{k},Accuracy:{accuracy}\")\n",
    "    \n",
    "    if accuracy>best_accuracy:\n",
    "        best_accuracy=accuracy\n",
    "        best_k=k\n",
    "        best_prediction=k_pred\n",
    "print()\n",
    "print(\"best_k\",best_k)\n",
    "print(\"best_accuracy\",best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(k_values,accuracy_values,marker='o')\n",
    "plt.title(\"Accuracy Vs Number of Neighbors(k)\")\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_model.fit(data_2d,label)\n",
    "new_image_path=[\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\cat3.jpg\"]\n",
    "new_data=[]\n",
    "for image_path in new_image_path:\n",
    "    preprocessed_image=preprocess_image(image_path)\n",
    "    new_data.append(preprocessed_image)\n",
    "new_data=np.array(new_data)\n",
    "#print(new_data)\n",
    "'''\n",
    "num_samples,h,w=new_data.shape\n",
    "new_data=new_data.reshape(num_samples,h*w)\n",
    "'''\n",
    "print(new_data.shape)\n",
    "new_pred=best_model.predict(new_data)\n",
    "print(new_pred)\n",
    "\n",
    "class_name=best_model.classes_\n",
    "predicted_class = new_pred[0]\n",
    "print(predicted_class)\n",
    "\n",
    "from PIL import Image\n",
    "test_image=Image.open(image_path)\n",
    "plt.imshow(test_image)\n",
    "plt.title(f\"Predicted_class:{class_names[predicted_class]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------ LINEAR CLASSIFIER--------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "lr=LogisticRegression()\n",
    "lr.fit(data_2d,label)\n",
    "lr_predict=lr.predict(data_test)\n",
    "lr_accuracyscore=accuracy_score(lr_predict,label_test)\n",
    "print(lr_accuracyscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI BATCH GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "label=le.fit_transform(label)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def cost_estimation(x,y,theta):\n",
    "    m=len(y)\n",
    "    h=sigmoid(x @ theta)\n",
    "    epsilon=1e-5\n",
    "    cost=(-1/m)*np.sum(y*np.log(h+epsilon)+(1-y) * np.log((1-h)+ epsilon)) \n",
    "    return cost\n",
    "\n",
    "bias_term=False\n",
    "if bias_term:\n",
    "    num_features=data_2d.shape[1]+1\n",
    "else:\n",
    "    num_features=data_2d.shape[1]\n",
    "    \n",
    "def mini_batch_gradient_descent(x,y,theta,learning_rate,batch_size,num_epochs):\n",
    "    m=len(y)\n",
    "    cost_history=[]\n",
    "    for num in range(num_epochs):\n",
    "        shuffle_indices=np.random.permutation(m)\n",
    "        x=x[shuffle_indices]\n",
    "        y=y[shuffle_indices]\n",
    "        for i in range(0,m,batch_size): # find the best theta\n",
    "            x_batch=x[i:i+batch_size]\n",
    "            y_batch=y[i:i+batch_size]\n",
    "            h=sigmoid(x_batch @ theta ) \n",
    "            gradient=(1/batch_size)*(x_batch.T @ (h-y_batch))\n",
    "            theta=theta-(learning_rate * gradient)\n",
    "        cost=cost_estimation(x,y,theta)\n",
    "        cost_history.append(cost)\n",
    "    return theta,cost_history\n",
    "\n",
    "                 \n",
    "        \n",
    "\n",
    "initial_theta=np.random.rand(num_features)\n",
    "learning_rate=0.01\n",
    "num_epoch=100\n",
    "batch_size=32\n",
    "best_theta,cost_history=mini_batch_gradient_descent(data_2d,label,initial_theta,learning_rate,batch_size,num_epoch)\n",
    "print(\"best_theta:\",best_theta)\n",
    "print()\n",
    "print(\"optimised cost=\",cost_history[-1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cost_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(num_epoch),cost_history)\n",
    "plt.title(\"mini batch gradient descent\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EARLY STOPPING METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "label=le.fit_transform(label)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def cost_estimation(x,y,theta):\n",
    "    m=len(y)\n",
    "    h=sigmoid(x @ theta)\n",
    "    epsilon=1e-5\n",
    "    cost=(-1/m)*np.sum(y*np.log(h+epsilon)+(1-y) * np.log((1-h)+ epsilon)) \n",
    "    return cost\n",
    "\n",
    "bias_term=False\n",
    "if bias_term:\n",
    "    num_features=data_2d.shape[1]+1\n",
    "else:\n",
    "    num_features=data_2d.shape[1]\n",
    "    \n",
    "def mini_batch_gradient_descent(x,y,theta,learning_rate,batch_size,num_epochs):\n",
    "    m=len(y)\n",
    "    cost_history=[]\n",
    "    best_cost=float(\"inf\")\n",
    "    count=0\n",
    "    for num in range(num_epochs):\n",
    "        shuffle_indices=np.random.permutation(m)\n",
    "        x=x[shuffle_indices]\n",
    "        y=y[shuffle_indices]\n",
    "        for i in range(0,m,batch_size): # find the best theta\n",
    "            x_batch=x[i:i+batch_size]\n",
    "            y_batch=y[i:i+batch_size]\n",
    "            h=sigmoid(x_batch @ theta ) \n",
    "            gradient=(1/batch_size)*(x_batch.T @ (h-y_batch))\n",
    "            theta=theta-(learning_rate * gradient)\n",
    "        cost=cost_estimation(x,y,theta)\n",
    "        cost_history.append(cost)\n",
    "        if cost<best_cost:\n",
    "            best_cost=cost\n",
    "            epoch=num\n",
    "            count=0\n",
    "        else:\n",
    "            count+=1\n",
    "            if count>=80:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    return theta,cost_history,best_cost,epoch\n",
    "\n",
    "                 \n",
    "        \n",
    "\n",
    "initial_theta=np.random.rand(num_features)\n",
    "learning_rate=0.01\n",
    "num_epoch=100\n",
    "batch_size=32\n",
    "best_theta,cost_history,best_cost,epoch=mini_batch_gradient_descent(data_2d,label,initial_theta,learning_rate,batch_size,num_epoch)\n",
    "print(\"best_theta:\",best_theta)\n",
    "print()\n",
    "print(\"optimised cost=\",best_cost)\n",
    "print()\n",
    "print(\"epoch=\",epoch)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(num_epoch),cost_history)\n",
    "plt.title(\"mini batch gradient descent\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "new_data_path=[\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\cat2.jpg\"]\n",
    "new_data=[]\n",
    "for image_path in new_data_path:\n",
    "    preprocessed_image=preprocess_image(image_path)\n",
    "    new_data.append(preprocessed_image)\n",
    "new_data=np.array(new_data)\n",
    "#print(new_data)\n",
    "\n",
    "#print(new_data.shape)\n",
    "\n",
    "def softmax(logits):\n",
    "    exp_logits=np.exp(logits-np.max(logits,keepdims=True))\n",
    "    probability=exp_logits/(np.sum(exp_logits,keepdims=True))\n",
    "    return probability\n",
    "\n",
    "\n",
    "\n",
    "logits=new_data @ best_theta\n",
    "probabilities=softmax(logits)\n",
    "print(len(probabilities))\n",
    "predicted_class=np.argmax(probabilities)\n",
    "print(predicted_class)\n",
    "#predicted_class=np.array(predicted_class)\n",
    "\n",
    "#name=le.inverse_transform(predicted_class)[0]\n",
    "print(predicted_class)\n",
    "\n",
    "\n",
    "print(f\" predicted_class {class_names[predicted_class]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINE(SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import os\n",
    "from skimage import io,transform,filters,color\n",
    "import numpy as np\n",
    "def preprocess_image(image_path):\n",
    "    image=io.imread(image_path)\n",
    "    image=color.rgb2gray(image)\n",
    "    image=filters.gaussian(image,sigma=1)\n",
    "    image=transform.resize(image,(100,100))\n",
    "    return image.flatten()\n",
    "train_folder=\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\training_set\"\n",
    "class_names=['cats','dogs']\n",
    "data=[]\n",
    "label=[]\n",
    "for class_name in class_names:\n",
    "    class_path=os.path.join(train_folder,class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "        if not image_name.startswith(\"_DS_Store\"):\n",
    "            image_path=os.path.join(class_path,image_name)\n",
    "            preprocessed_image=preprocess_image(image_path)\n",
    "            data.append(preprocessed_image)\n",
    "            label.append(class_name)\n",
    "data=np.array(data)\n",
    "label=np.array(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder=\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\test_set\"\n",
    "class_names=['cats','dogs']\n",
    "data_test=[]\n",
    "label_test=[]\n",
    "for class_name in class_names:\n",
    "    class_path=os.path.join(test_folder,class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "        if not image_name.startswith(\"_DS_Store\"):\n",
    "            image_path=os.path.join(class_path,image_name)\n",
    "            preprocessed_image=preprocess_image(image_path)\n",
    "            data_test.append(preprocessed_image)\n",
    "            label_test.append(class_name)\n",
    "data_test=np.array(data_test)\n",
    "label_test=np.array(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "le=LabelEncoder()\n",
    "label=le.fit_transform(label)\n",
    "label_test=le.fit_transform(label_test)\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train,data_test,label_train,label_test=train_test_split(data,label,test_size=0.2)\n",
    "st=StandardScaler()\n",
    "data=st.fit_transform(data)\n",
    "data_test=st.transform(data_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "svm_classifier=SVC(kernel='rbf',C=0.1,gamma=0.1)\n",
    "svm_classifier.fit(data,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predict=svm_classifier.predict(data_test)\n",
    "print(\"accuracy_score=\",accuracy_score(svm_predict,label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_paths=[\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\dog2.jpg\"]\n",
    "for image_path in image_paths:\n",
    "    image=io.imread(image_path)\n",
    "    gray_image=color.rgb2gray(image)\n",
    "\n",
    "    plt.hist(gray_image.ravel(),bins=256,range=(0.0,1.0),color=\"gray\")\n",
    "    plt.title(\"histogram of an image\")\n",
    "    plt.xlabel(\"color intensity\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image_paths=[\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\dog2.jpg\"]\n",
    "for image_path in image_paths:\n",
    "    image=io.imread(image_path)\n",
    "    red_channel,bin_edge=np.histogram(image[:,:,0],bins=256,range=(0,256))\n",
    "    green_channel,_=np.histogram(image[:,:,1],bins=256,range=(0,256))\n",
    "    blue_channel,_=np.histogram(image[:,:,2],bins=256,range=(0,256))\n",
    "    \n",
    "    red_channel=red_channel/red_channel.sum()\n",
    "    green_channel=green_channel/green_channel.sum()\n",
    "    blue_channel=blue_channel/blue_channel.sum()\n",
    "    \n",
    "    plt.plot(red_channel,color='red',label='RED channel',alpha=1)\n",
    "    plt.plot(green_channel,color='green',label='GREEN channel',alpha=1)\n",
    "    plt.plot(blue_channel,color='blue',label='BLUE channel',alpha=1)\n",
    "\n",
    "\n",
    "    plt.title(\"histogram of an  image\")\n",
    "    plt.xlabel(\"color intensity\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,colmn=image.shape[:2] # histogram of an sub images\n",
    "mid=rows//2\n",
    "top_image=image[:mid,:]\n",
    "bottom_image=image[mid:,:]\n",
    "middle=colmn//2\n",
    "left_image=image[:,:middle]\n",
    "right_image=image[:,middle:]\n",
    "\n",
    "subimages=[top_image,bottom_image,left_image,right_image]\n",
    "\n",
    "for i ,subimage in enumerate (subimages):\n",
    "    \n",
    "    red_channel,bin_edge=np.histogram(subimage[:,:,0],bins=256,range=(0,256))\n",
    "    green_channel,_=np.histogram(subimage[:,:,1],bins=256,range=(0,256))\n",
    "    blue_channel,_=np.histogram(subimage[:,:,2],bins=256,range=(0,256))\n",
    "    \n",
    "    red_channel=red_channel/red_channel.sum()\n",
    "    green_channel=green_channel/green_channel.sum()\n",
    "    blue_channel=blue_channel/blue_channel.sum()\n",
    "    \n",
    "    plt.plot(red_channel,color='red',label='RED channel',alpha=1)\n",
    "    plt.plot(green_channel,color='green',label='GREEN channel',alpha=1)\n",
    "    plt.plot(blue_channel,color='blue',label='BLUE channel',alpha=1)\n",
    "\n",
    "\n",
    "    plt.title(f\"histogram of an  subimage {i+1}\")\n",
    "    plt.xlabel(\"color intensity\")\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOG Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io,color\n",
    "from skimage.filters import sobel\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "image_folder=\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\training_set\"\n",
    "\n",
    "def preprocess(image_path):\n",
    "    image=io.imread(image_path)\n",
    "    gray_image=color.rgb2gray(image)\n",
    "    gray_image=resize(gray_image,(100,100))\n",
    "    gradient_magnitude=sobel(gray_image)\n",
    "    gradient_direction=np.arctan2(sobel(gray_image,axis=0),sobel(gray_image,axis=1))\n",
    "    hog_feature=hog(gradient_magnitude,block_norm='L2-Hys',pixels_per_cell=(16,16),cells_per_block=(1,1))\n",
    "    return hog_feature.flatten()\n",
    "\n",
    "features=[]\n",
    "class_names=['cats','dogs']\n",
    "for class_name in class_names:\n",
    "    class_path=os.path.join(image_folder,class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "        if not image_name.startswith('_DS_Store'):\n",
    "            image_path=os.path.join(class_path,image_name)\n",
    "            feature=preprocess(image_path)\n",
    "            features.append(feature)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data=np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "le=LabelEncoder()\n",
    "label=le.fit_transform(label)\n",
    "from sklearn.model_selection import train_test_split\n",
    "feature_train,feature_test,l_train,l_test=train_test_split(features_data,label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_param={'C':[0.001,0.01,0.1,1,10],\n",
    "            'gamma':[0.001,0.01,0.1,1,10]}\n",
    "svm_classifier=SVC(kernel='rbf')\n",
    "gridsearch=GridSearchCV(svm_classifier,grid_param,cv=5)\n",
    "gridsearch.fit(feature_train,l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best parameter:\",gridsearch.best_params_)\n",
    "print(\"best cross validation score=\",gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param={'C':[0.001,0.01,0.1,1,10],\n",
    "            'gamma':[0.001,0.01,0.1,1,10]}\n",
    "svm_classifier=SVC(kernel='rbf')\n",
    "randomsearch=RandomizedSearchCV(svm_classifier,param,cv=5)\n",
    "randomsearch.fit(feature_train,l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best parameter:\",randomsearch.best_params_)\n",
    "print(\"best cross validation score=\",randomsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "svm_classifier=SVC(kernel='rbf',C=10,gamma=0.1)\n",
    "svm_classifier.fit(feature_train,l_train)\n",
    "svm_predict=svm_classifier.predict(feature_test)\n",
    "print(\"accuracy_score=\",accuracy_score(svm_predict,l_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without manually specifies the \"C\" and \"gamma\" value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier_w=SVC(kernel='rbf')\n",
    "svm_classifier_w.fit(feature_train,l_train)\n",
    "svm_predict=svm_classifier_w.predict(feature_test)\n",
    "print(\"accuracy_score=\",accuracy_score(svm_predict,l_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(l_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = 0\n",
    "n = 0\n",
    "misclassified_points = []\n",
    "correct_classified_points = []\n",
    "\n",
    "for i in range(len(l_test)):\n",
    "    if svm_predict[i] == l_test[i]:\n",
    "        m += 1\n",
    "        correct_classified_points.append((i, m))\n",
    "    else:\n",
    "        n += 1\n",
    "        misclassified_points.append((i, n))\n",
    "\n",
    "print(\"Misclassified amount:\", n)\n",
    "print(\"Correct classified amount:\", m)\n",
    "\n",
    "\n",
    "misclassified_x, misclassified_y = zip(*misclassified_points)\n",
    "correct_classified_x, correct_classified_y = zip(*correct_classified_points)\n",
    "print(misclassified_x)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(misclassified_x, misclassified_y, color='red', marker='x', label='Misclassified')\n",
    "plt.scatter(correct_classified_x, correct_classified_y, color='green', marker='o', label='Correct Classified')\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Cumulative Count\")\n",
    "plt.title(\"Misclassified and Correct Classified Samples\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_path=[\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\dog2.jpg\"]\n",
    "new_data=[]\n",
    "for image_path in new_data_path:\n",
    "    features_new_data=preprocess(image_path)\n",
    "    new_data.append(features_new_data)\n",
    "new_data=np.array(new_data)\n",
    "\n",
    "svm_predict=svm_classifier_w.predict(new_data)\n",
    "#print(svm_predict)\n",
    "predicted_class=class_names[svm_predict[0]]\n",
    "#print(predicted_class)\n",
    "\n",
    "from PIL import Image\n",
    "new_image=Image.open(new_data_path[0])\n",
    "plt.title(f\"predicted class:{predicted_class}\") \n",
    "plt.imshow(new_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Direction of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"C:\\\\Users\\\\User\\\\Documents\\\\digital image processing\\\\New folder\\\\data\\\\dog2.jpg\"\n",
    "\n",
    "from skimage.filters import sobel\n",
    "from skimage import color\n",
    "import numpy as np\n",
    "\n",
    "image=io.imread(image_path)\n",
    "gray_image=color.rgb2gray(image)\n",
    "#magnitude=sobel(image)\n",
    "gradient_direction=np.arctan2(sobel(gray_image,axis=0),sobel(gray_image,axis=1))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(gradient_direction,cmap='hsv',vmin=-np.pi,vmax=np.pi)\n",
    "plt.colorbar(label='gradient direction(radians)')\n",
    "plt.title(\"Gradient direction\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "knn=KNeighborsClassifier(n_neighbors=2)\n",
    "svm=SVC(kernel='rbf')\n",
    "lr=LogisticRegression()\n",
    "vlf=VotingClassifier(estimators=[('rf',rf),('knn',knn),('svm',svm),('lr',lr)],voting='hard')\n",
    "vlf.fit(feature_train,l_train)\n",
    "for clf in (rf,knn,svm,lr,vlf):\n",
    "    clf.fit(feature_train,l_train)\n",
    "    clf_predict=clf.predict(feature_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(clf_predict,l_test))\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
